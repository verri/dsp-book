\chapter{Preliminaries}
\label{chap:preliminaries}

\chapterprecishere{%
  Maar ik maak steeds wat ik nog niet kan om het te leeren kunnen.\par\raggedleft---
  \textup{Vincent van Gogh}, The Complete Letters of Vincent Van Gogh, Volume Three}

Foundamental concepts in data science come from a variety of fields, including
mathematics, statistics, computer science, optimization theory, and information theory.
This chapter provides a brief overview of the computational, mathematical and statistical
concepts that are used in the rest of the book.

\section{Algorithms and data structures}

Algorithms are step-by-step procedures for solving a problem.  They are used to
manipulate data structures, which are ways of organizing data to solve problems.
They are realized in programming languages, which are formal languages that can be used
to express algorithms.

\subsection{Algoritmic paradigms}

Some techniques are used to solve a wide variety of problems.  They are called
algorithmic paradigms.  The most common ones are listed below.

\paragraph{Divide and conquer}  The problem is divided into smaller subproblems that are
solved recursively.  The solutions to the subproblems are then combined to give a solution
to the original problem.  Some example algorithms are merge sort, quick sort, and binary
search.

% \paragraph{Dynamic programming}  The problem is divided into overlapping subproblems, and
% the solutions to the subproblems are only solved once. The subproblems are then optimized
% to find the overall solution.  Some example algorithms are the Bellman-Ford algorithm,
% Floyd-Warshall algorithm, and the Knapsack problem.

\paragraph{Greedy algorithms}  The problem is solved with incremental steps, each of which
is locally optimal.  The overall solution is not guaranteed to be (but might be) optimal.  Some example
algorithms are Dijkstra's algorithm and Prim's algorithm

\paragraph{Backtracking}  The problem is solved incrementally, one piece at a time.  If a
piece does not fit, it is removed and replaced by another piece.  Some example algorithms
are the naÃ¯ve solutions for N-queens problem and the Sudoku problem.

\subsection{Computational complexity}

The computational complexity of an algorithm is the amount of resources it uses to
run as a function of the size of the input.  The most common resources are time and
space.

Usually, we are interested in the asymptotic complexity of an algorithm, i.e. how
the complexity grows as the size of the input grows.  The most common notation for
asymptotic complexity is the Big-O notation.

\paragraph{Big-O notation}  Let $f$ and $g$ be functions from the set of natural numbers
to the set of real numbers, i.e. $f, g : \mathbb{N} \rightarrow \mathbb{R}$.  We say that $f$ is
$O(g)$ if there exists a constant $c > 0$ such that $f(n) \leq c g(n)$ for all $n \geq
n_0$, where $n_0$ is a natural number.

We can order functions by their asymptotic complexity.  For example, $O(1) < O(\log n) <
O(n) < O(n \log n) < O(n^2) < O(2^n) < O(n!)$.  The Big-O notation is used to describe
the asymptotic complexity of algorithms.

\subsection{Data structures}

Data structures are ways of organizing data to solve problems.  The most common ones
are listed below.

\paragraph{Arrays}  An array is a homogeneous collection of elements that are accessed by
an integer index.  The elements are usually stored in contiguous memory locations.

\paragraph{Linked lists}  A linked list is a collection of elements called nodes.  Each
node contains a value and a pointer to the next node in the list.  The first node is
called the head, and the last node is called the tail.  The tail points to a null
reference.

\paragraph{Stacks}  A stack is a collection of elements that are accessed in a
last-in-first-out (LIFO) order.  Elements are added to the top of the stack and
removed from the top of the stack.

\paragraph{Queues}  A queue is a collection of elements that are accessed in a
first-in-first-out (FIFO) order.  Elements are added to the back of the queue and
removed from the front of the queue.

\paragraph{Trees}  A tree is a collection of nodes.  Each node contains a value and a
list of references to its children.  The first node is called the root.  A node with
no children is called a leaf.

\paragraph{Graphs}  A graph is a collection of nodes.  Each node contains a value and a
list of references to its neighbors; the references are called edges.  A graph can be
directed or undirected.  A graph is directed if the edges have a direction.

\paragraph{Map} A map is a collection of key-value pairs.  The keys are unique, and
each key is associated with a value.  The keys are used to access the values.

\section{Set theory}

A set is a collection of elements.  The elements of a set can be anything, including
other sets.  The elements of a set are unordered, and each element is unique.  The
most common notation for sets is the curly braces notation, e.g. $\{1, 2, 3\}$.

\subsection{Set operations}

\paragraph{Union}  The union of two sets $A$ and $B$ is the set of elements that are in
$A$ or $B$.  It is denoted by $A \cup B$.

\paragraph{Intersection}  The intersection of two sets $A$ and $B$ is the set of elements
that are in both $A$ and $B$.  It is denoted by $A \cap B$.

\paragraph{Difference}  The difference of two sets $A$ and $B$ is the set of elements
that are in $A$ but not in $B$.  It is denoted by $A \setminus B$.

Union and intersection are commutative, associative and distributive.

\paragraph{Universe set}  The universe set is the set of all elements.  It is denoted
by $\Omega$.

\paragraph{Empty set}  The empty set is the set with no elements.  It is denoted by
$\emptyset$.

\paragraph{Complement}  The complement of a set $A$ is the set of elements that are not
in $A$.  It is denoted by $A^c = \Omega \setminus A$.

\paragraph{Inclusion}  Given sets $A$, $B$, and $C$, the following statements hold:
\begin{itemize}
  \item \emph{Reflexity:} $A \subseteq A$;
  \item \emph{Antisymmetry:} $A \subseteq B$ and $B \subseteq A$ if and only if $A = B$;
  \item \emph{Transitivity:} $A \subseteq B$ and $B \subseteq C$ implies $A \subseteq C$.
\end{itemize}

\section{Linear algebra}

\paragraph{Vector}  A vector is an ordered collection of numbers.  It is denoted by a bold
lowercase letter, e.g. $\vec{v} = (v_i)_{i= 1,\dots, n}$ is a vector of length $n$.

\paragraph{Matrix}  A matrix is a rectangular collection of numbers.  It is denoted by an
uppercase letter, e.g. $A = (a_{ij})_{i = 1, \dots, n;~j = 1, \dots, m}$ is the matrix
with $n$ rows and $m$ columns.

\subsection{Matrix decompositions}

Matrix decompositions are factorizations of matrices into matrices with special
properties.  They are used to solve linear systems, compute inverses, and compute
eigenvalues and eigenvectors.

\textcolor{red}{Verify!}

\paragraph{Singular value decomposition} The singular value decomposition (SVD) of a
matrix $A$ is a factorization of the form
\begin{equation}
  \label{eq:svd}
  A = U \Sigma V^T\text{,}
\end{equation}
where $U$ and $V$ are orthogonal matrices and $\Sigma$ is a diagonal
matrix with non-negative real numbers on the diagonal.  The singular values are the
diagonal entries of $\Sigma$.

\paragraph{Eigenvalue decomposition}  The eigenvalue decomposition of a matrix $A$
is a factorization of the form
\begin{equation}
  \label{eq:eigdec}
  A = Q \Lambda Q^{-1}\text{,}
\end{equation}
where $Q$ is a square matrix whose columns are the eigenvectors of $A$, and
$\Lambda$ is a diagonal matrix whose diagonal entries are the eigenvalues of
$A$.

\paragraph{Cholesky decomposition}  The Cholesky decomposition of a positive-definite
matrix $A$ is a factorization of the form
\begin{equation}
  \label{eq:chol}
  A = L L^T\text{,}
\end{equation}
where $L$ is a lower triangular matrix with real and positive diagonal entries.

\paragraph{QR decomposition}  The QR decomposition of a matrix $A$ is a
factorization of the form
\begin{equation}
  \label{eq:qr}
  A = Q R\text{,}
\end{equation}
where $Q$ is an orthogonal matrix and $R$ is an upper triangular matrix.

\paragraph{LU decomposition}  The LU decomposition of a square matrix $A$ is a
factorization of the form
\begin{equation}
  \label{eq:lu}
  A = L U\text{,}
\end{equation}
where $L$ is a lower triangular matrix with unit diagonal entries and $U$ is
an upper triangular matrix.

\subsection{Eigenvalues and eigenvectors}

An eigenvalue of a square matrix $A$ is a scalar $\lambda$ such that there exists a
non-zero vector $\vec{v}$ satisfying
\begin{equation}
  \label{eq:eig}
  A \vec{v} = \lambda \vec{v}\text{.}
\end{equation}
The vector $\vec{v}$ is called an eigenvector of $A$ corresponding to $\lambda$.

\section{Probability}

The Kolmogorov axioms of probability are the foundation of probability theory.
They are
\begin{enumerate}
  \item The probability of an event $A$ is a non-negative real number, i.e. $P(A) \geq 0$;
  \item The probability of the sample space $\Omega$ is one, i.e. $P(\Omega) = 1$; and
  \item The probability of the union of disjoint events, $A \cap B = \emptyset$, is
    the sum of the probabilities of the events, i.e. $P(A \cup B) = P(A) + P(B)$.
\end{enumerate}

If $A$ and $B$ are not disjoint, then
\begin{equation*}
  P(A \cup B) = P(A) + P(B) - P(A \cap B)\text{.}
\end{equation*}

\paragraph{Joint probability}

The joint probability of two events $A$ and $B$ is the probability that both events
occur.  It is denoted by $P(A, B) = P(A \cap B)$.

\paragraph{Law of total probability}

The law of total probability states that if $B_1, \dots, B_n$ are disjoint events
such that $\cup_{i = 1}^n B_i = \Omega$, then for any event $A$, we have that
$$P(A) = \sum_{i = 1}^n P(A, B_i)\text{.}$$

\paragraph{Conditional probability}

The conditional probability of an event $A$ given an event $B$ is the probability
that $A$ occurs given that $B$ occurs.  It is denoted by $P(A \mid B)$.

\paragraph{Independence}

Two events $A$ and $B$ are independent if the probability of $A$ given $B$ is the
same as the probability of $A$, i.e. $P(A \mid B) = P(A)$.  It is equivalent to
$P(A, B) = P(A) \cdot P(B)$.

\paragraph{Bayes' rule}

Bayes' rule is a formula that relates the conditional probability of an event $A$
given an event $B$ to the conditional probability of $B$ given $A$.  It is
\begin{equation}
  \label{eq:bayes}
  P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}\text{.}
\end{equation}

\subsection{Random variables}

A random variable is a function that maps the sample space $\Omega$ to the real
numbers.  It is denoted by a capital letter, e.g. $X$.

Formally, let $X : \Omega \rightarrow E$ be a random variable.  The
probability that $X$ takes on a value in a set $A \subseteq E$ is
\begin{equation}
  \label{eq:rv}
  P(X \in A) = P(\{\omega \in \Omega : X(\omega) \in A\})\text{.}
\end{equation}

If $E = \mathbb{R}$, then $X$ is a continuous random variable.  If $E = \mathbb{Z}$,
then $X$ is a discrete random variable.

\paragraph{Probability mass function}

The probability mass function (PMF) of a discrete random variable $X$ is the
function $p_X : \mathbb{R} \rightarrow [0, 1]$ defined by
\begin{equation}
  \label{eq:pmf}
  p_X(x) = P(X = x)\text{.}
\end{equation}

\paragraph{Probability density function}

The probability density function (PDF) of a continuous random variable $X$ is the
function $f_X : \mathbb{R} \rightarrow [0, \infty)$ defined by
\begin{equation}
  \label{eq:pdf}
  P(a \leq X \leq b) = \int_a^b f_X(x) dx\text{.}
\end{equation}

\paragraph{Cumulative distribution function}

The cumulative distribution function (CDF) of a random variable $X$ is the function
$F_X : \mathbb{R} \rightarrow [0, 1]$ defined by
\begin{equation}
  \label{eq:cdf}
  F_X(x) = P(X \leq x)\text{.}
\end{equation}

\subsection{Expectation and moments}

Expectation is a measure of the average value of a random variable.  Moments are
measures of the shape of a probability distribution.

\paragraph{Expectation}  The expectation of a random variable $X$ is the average
value of $X$.  It is denoted by $E[X]$.  By definition, it is
\begin{equation}
  \label{eq:expectation}
  E[X] = \begin{dcases}
    \sum_{x} x \cdot p_X(x) & \text{if $X$ is discrete; } \\
    \int_{-\infty}^{\infty} x \cdot f_X(x) dx & \text{if $X$ is continuous.}
  \end{dcases}
\end{equation}

\paragraph{Variance}  The variance of a random variable $X$ is a measure of how
spread out the values of $X$ are.  It is denoted by $V(X)$.  By definition, it is
\begin{equation}
  \label{eq:variance}
  V(X) = E\!\left[\left(X - E[X]\right)^2\right]\text{.}
\end{equation}

Higher moments are defined similarly, look for skewness and kurtosis.

\subsection{Probability distributions}

Several phenomena in nature and society can be modeled as random variables.  Some
distributions are frequently used to model these phenomena.  The main ones are
listed below.

\paragraph{Bernoulli distribution}  The Bernoulli distribution is a discrete
distribution with two possible outcomes, usually called success and failure.  It is
parametrized by a single parameter $p \in [0, 1]$, which is the probability of
success.  It is denoted by $\text{Bern}(p)$.

The expected value of $X \sim \text{Bern}(p)$ is $E[X] = p$, and the variance is
$V(X) = p(1 - p)$.

\paragraph{Normal distribution} The normal distribution is a continuous distribution
with a bell-shaped density.  It is parametrized by two parameters, the mean $\mu \in
\mathbb{R}$ and the standard deviation $\sigma > 0$.  It is denoted by
$\mathcal{N}(\mu, \sigma^2)$.

The special case where $\mu = 0$ and $\sigma = 1$ is called the standard normal
distribution.  It is denoted by $\mathcal{N}(0, 1)$.

The probability density function of $X \sim \mathcal{N}(\mu, \sigma^2)$ is
\begin{equation}
  \label{eq:normal}
  f_X(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{(x - \mu)^2}{2 \sigma^2}\right)\text{.}
\end{equation}

The expected value of $X \sim \mathcal{N}(\mu, \sigma^2)$ is $E[X] = \mu$, and the
variance is $V(X) = \sigma^2$.

\paragraph{T distribution} The T distribution is a continuous distribution with a
bell-shaped density.  It is parametrized by a single parameter $\nu > 0$, called the
degrees of freedom.  It is denoted by $\mathcal{T}(\nu)$.

% The probability density function of $X \sim \mathcal{T}(\nu)$ is
% \begin{equation}
%   \label{eq:t}
%   f_X(x) = \frac{\Gamma\left(\frac{\nu + 1}{2}\right)}{\sqrt{\nu \pi} \Gamma\left(\frac{\nu}{2}\right)}
%   \left(1 + \frac{x^2}{\nu}\right)^{-\frac{\nu + 1}{2}}\text{.}
% \end{equation}

The T distribution generalizes to the three parameter location-scale t distribution
$\mathcal{T}(\mu, \sigma^2, \nu)$, where $\mu$ is the location parameter and $\sigma$ is
the scale parameter.  Thus, given $X \sim \mathcal{T}(\nu)$, we have that
$\mu + \sigma X \sim \mathcal{T}(\mu, \sigma^2, \nu)$.

Note that $$\lim_{\nu \rightarrow \infty} \mathcal{T}(\nu) = \mathcal{N}(0, 1)\text{.}$$

\subsection{Permutations and combinations}

\paragraph{Permutation}  A permutation is an arrangement of a set of elements.  The
number of permutations of $n$ elements is $n!$.

\paragraph{Combination}  A combination is a selection of a subset of elements from a
set.  The number of combinations of $k$ elements from a set of $n$ elements is
$$\binom{n}{k} = \frac{n!}{k!(n - k)!}\text{.}$$

\section{Optimization}

Optimization is the process of finding the best solution to a problem.  The best
solution is called the (global) optimum.  The optimum can be a maximum or a minimum.
Sometimes, we are interested in finding a local optimum, which is the best solution
in a neighborhood of the current solution.  Also, we might be interested in finding
a solution that is good enough, i.e. a solution that is close to the optimum.
In this case, we use heuristics to search in the solution space.

\subsection{Minimization of convex functions}

Maybe the simplest case of optimization is the minimization of a convex function.
A function $f : \mathbb{R}^n \rightarrow \mathbb{R}$ is convex if for any two points
$\vec{v}$ and $\vec{w}$ in the domain of $f$, the line segment connecting them lies
above the graph of $f$.  Mathematically, it means that
$$f(t\vec{v} + (1 - t) \vec{w}) \leq t f(\vec{v}) + (1 - t) f(\vec{w})$$ for all $t \in [0, 1]$.

\subsection{Gradient descent}

Gradient descent is an iterative algorithm for finding the minimum of a function.
It is based on the observation that the gradient of a function points in the
direction of the steepest descent.  The algorithm is
\begin{equation}
  \label{eq:gd}
  \vec{w}(t + 1) = \vec{w}(t) - \alpha \nabla f(\vec{w}(t))\text{,}
\end{equation}

\subsection{Constraint optimization}

Techniques like Lagrange multipliers, penalty methods, and barrier methods are used to
handle constrained optimization problems in data science.

\subsection{Convex optimization}

Convex optimization problems, where the objective function and the constraints are convex,
have efficient algorithms that guarantee global optimality.

% \subsection{Gradient descent algorithm}
%
% Let $f(\vec{w})$, $f : \mathbb{R}^n \rightarrow \mathbb{R}$, be an objective function that
% we are trying to minimize.  We know that
% $f$ is convex, of class $\mathcal{C}^2$, and its gradient $\nabla f$ is Lipschitz continuous with Lipschitz
% constant $L > 0$.
%
% We want to show that $\lim_{t\rightarrow\infty} f(\vec{w}(t)) = f^{*}$ where $f^{*}$
% is the global minimum of $f$ and $$\vec{w}(t+1) = \vec{w}(t) - \alpha \nabla f(\vec{w}(t))\mbox{,}$$
% for any initial condition $\vec{w}(0)$ and $0 < \alpha \leq \frac{1}{L}$.
%
% Convexity implies that for any two points $\vec{v}$ and $\vec{w}$ in the domain of
% $f$, the line segment connecting them lies above the graph of $f$.  Mathematically, it
% means that $$f(t\vec{v} + (1 - t) \vec{w}) \leq t f(\vec{v}) + (1 - t)
% f(\vec{w})$$ for all $t \in [0, 1]$.
%
% The Lipschitz continuity condition means that the gradient of $f(\vec{w})$ does not change too rapidly.
% Formally, $$\left\|\nabla f(\vec{v}) - \nabla f(\vec{w})\right\| \leq L \|\vec{v} - \vec{w}\|\mbox{,}$$
% for all $\vec{v}$ and $\vec{w}$ in the domain of $f$.  This is a rather weak
% assumption, and it means that the gradient can not change arbitrarily fast.
%
% Since $f$ is convex and twice differentiable, its Hessian is a positive semidefinite
% matrix, and thus its norm is its largest eigenvalue.
%
% A consequence of the Lipschitz continuity for a $\mathcal{C}^2$ function $f$ is that for
% any $\vec{v}$ and $\vec{w}$, we have that
% \begin{equation}
%   \label{eq:lcg1}
%   \vec{v}^T \nabla^2 f(w) \vec{v} \leq L \|v\|^2\text{.}
% \end{equation}
% It means that the eigenvalues of the Hessian are bounded above by $L$.
%
% \paragraph{Descent lemma.}  For $f$, a the multivariate Taylor expansion is that
% $$f(w) = f(v)$$
